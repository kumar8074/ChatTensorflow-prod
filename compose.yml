services:
  # OpenSearch
  opensearch:
    image: opensearchproject/opensearch:2.19.0
    container_name: chatTF-opensearch
    environment:
      - discovery.type=single-node
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=${OPENSEARCH_PASS:-Admin@123}
      - DISABLE_SECURITY_PLUGIN=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
      - "9600:9600"
    volumes:
      - opensearch-data:/usr/share/opensearch/data
    networks:
      - chatTF-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # OpenSearch Dashboards
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2.19.0
    container_name: chatTF-opensearch-dashboards
    ports:
      - "5601:5601"
    environment:
      - OPENSEARCH_HOSTS=http://opensearch:9200
      - DISABLE_SECURITY_DASHBOARDS_PLUGIN=true
    depends_on:
      opensearch:
        condition: service_healthy
    networks:
      - chatTF-network

# Airflow PostgreSQL
  airflow-postgres:
    image: postgres:16
    container_name: chatTF-airflow-db
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow-db-data:/var/lib/postgresql/data
    networks:
      - chatTF-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Airflow Init
  airflow-init:
    build:
      context: .
      dockerfile: airflow/Dockerfile
    container_name: chatTF-airflow-init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db migrate
        airflow users create \
          --username admin \
          --password admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com || true
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW_UID=50000
    user: "50000:0"
    volumes:
      - airflow-logs:/opt/airflow/logs
    depends_on:
      airflow-postgres:
        condition: service_healthy
    networks:
      - chatTF-network

  # Airflow Webserver
  airflow-webserver:
    build:
      context: .
      dockerfile: airflow/Dockerfile
    container_name: chatTF-airflow-webserver
    command: webserver
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    ports:
      - "8080:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW_WEBSERVER_SECRET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - OPENSEARCH_HOST=${OPENSEARCH_HOST:-opensearch:9200}
      - OPENSEARCH_USER=${OPENSEARCH_USER:-admin}
      - OPENSEARCH_PASS=${OPENSEARCH_PASS:-admin}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - PYTHONPATH=/opt/airflow
      - AIRFLOW_UID=50000
    user: "50000:0"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./temp:/opt/airflow/temp
      - airflow-logs:/opt/airflow/logs
    depends_on:
      airflow-postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    networks:
      - chatTF-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Airflow Scheduler
  airflow-scheduler:
    build:
      context: .
      dockerfile: airflow/Dockerfile
    container_name: chatTF-airflow-scheduler
    command: scheduler
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__PARALLELISM=16
      - AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG=4
      - AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT=90
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - OPENSEARCH_HOST=${OPENSEARCH_HOST:-opensearch:9200}
      - OPENSEARCH_USER=${OPENSEARCH_USER:-admin}
      - OPENSEARCH_PASS=${OPENSEARCH_PASS:-admin}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - PYTHONPATH=/opt/airflow
      - AIRFLOW_UID=50000
    user: "50000:0"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./temp:/opt/airflow/temp
      - airflow-logs:/opt/airflow/logs
    depends_on:
      airflow-postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    networks:
      - chatTF-network

  # FastAPI Application
  fastapi-app:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        VERSION: ${APP_VERSION:-0.1.0}
    container_name: chatTF-fastapi
    ports:
      - "8000:8000"
    environment:
      - OPENSEARCH_HOST=opensearch:9200
      - OPENSEARCH_USER=${OPENSEARCH_USER:-admin}
      - OPENSEARCH_PASS=${OPENSEARCH_PASS:-admin}
      - OPENSEARCH_INDEX_NAME=${OPENSEARCH_INDEX_NAME:-tensorflow_docs}
      - OPENSEARCH_USE_SSL=${OPENSEARCH_USE_SSL:-false}
      - OPENSEARCH_VERIFY_CERTS=${OPENSEARCH_VERIFY_CERTS:-false}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}  
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2:-true}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
      - LANGCHAIN_PROJECT=${LANGCHAIN_PROJECT}   
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2'
        reservations:
          memory: 1G
          cpus: '0.5'
    volumes:
      - ./logs:/app/logs
      - ./temp:/app/temp
    depends_on:
      opensearch:
        condition: service_healthy
    networks:
      - chatTF-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/docs || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    restart: unless-stopped

volumes:
  opensearch-data:
  airflow-db-data:
  airflow-logs:

networks:
  chatTF-network:
    driver: bridge